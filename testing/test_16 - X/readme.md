encoder layers: non-trainable
LSTM: 2
neurons_1: 128
neurons_2: 64.0
epochs: 20
autoencoder batch_size: 128
n_clusters: 7
clusters batch_size: 256
max iterations: 8000
tolerance threshold: 0.001
regularizers.l1(10e-4): LSTM layer 2
Autoencoder training time: 3570.1188665
Clustering training time: 10029.472395896912
0    0.145283
1    0.145819
2    0.145114
3    0.145258
4    0.145859
5    0.145876
6    0.145273
dtype: float64
0    12057
5     5791
4      253
2      110
6       37
Name: 7, dtype: int64
