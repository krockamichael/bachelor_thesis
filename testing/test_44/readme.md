encoder layers: non-trainable
LSTM: 2
neurons_1: 128
neurons_2: 64.0
epochs: 20
autoencoder batch_size: 128
n_clusters: 10
clusters batch_size: 256
max iterations: 8000
tolerance threshold: 0.001
regularizers.l1(10e-5): LSTM layer 2
iteration: 140
delta_label: 0.0
Clustering training time: 315.38576006889343
0    0.102799
1    0.106874
2    0.104057
3    0.106553
4    0.103610
5    0.104158
6    0.105592
7    0.105151
8    0.103043
9    0.113060
dtype: float64
0    9083
8    2529
4    1994
5    1073
3     857
7     804
6     616
2     608
1     565
9     119
Name: 10, dtype: int64
