encoder layers: non-trainable
LSTM: 2
neurons_1: 128
neurons_2: 64.0
epochs: 20
autoencoder batch_size: 128
n_clusters: 7
clusters batch_size: 256
max iterations: 8000
tolerance threshold: 0.001
regularizers.l1(10e-5): LSTM layer 2
dropout(0.2): LSTM layer 2
Autoencoder training time: 3611.7793021
Clustering training time: 10064.97744178772
0    0.162387
1    0.150557
2    0.163110
3    0.150768
4    0.160072
5    0.151157
6    0.150867
dtype: float64
2    14160
6     2021
5     1696
1      317
4       49
3        5
Name: 7, dtype: int64
