encoder layers: non-trainable
LSTM: 2
neurons_1: 128
neurons_2: 64.0
epochs: 20
autoencoder batch_size: 128
n_clusters: 7
clusters batch_size: 256
max iterations: 8000
tolerance threshold: 0.001
regularizers.l1(10e-6): LSTM layer 2
Autoencoder training time: 3525.379506599999
Clustering training time: 9466.073182821274
0    0.216911
1    0.217092
2    0.213412
3    0.185840
4    0.233734
5    0.189124
6    0.191911
dtype: float64
4    9566
2    4750
6    3441
1     491
Name: 7, dtype: int64
