encoder layers: non-trainable
LSTM: 3
neurons_1: 128
neurons_2: 64.0
neurons_3: 32.0
epochs: 20
autoencoder batch_size: 128
n_clusters: 7
clusters batch_size: 256
max iterations: 8000
tolerance threshold: 0.001
regularizers.l1(10e-5): LSTM layer 2
Autoencoder training time: 6536.806494099999
iteration: 140
delta_label: 0.07102148180622533
iteration: 280
delta_label: 0.5234546251644016
iteration: 420
delta_label: 0.10044936431389741
iteration: 560
delta_label: 0.7546032441911442
iteration: 700
delta_label: 0.7854011398509426
iteration: 840
delta_label: 0.7383274879438843
iteration: 980
delta_label: 0.7933472161332749
iteration: 1120
delta_label: 0.7933472161332749
iteration: 1260
delta_label: 0.8245835160017536
iteration: 1400
delta_label: 0.10664182376150812
iteration: 1540
delta_label: 0.7234765453748356
iteration: 1680
delta_label: 0.034853134590092066
iteration: 1820
delta_label: 0.5165497588776852
iteration: 1960
delta_label: 0.19059622972380535
iteration: 2100
delta_label: 0.7419991231915827
iteration: 2240
delta_label: 0.7419991231915827
Clustering training time: 4328.6983761787415
0    0.143499
1    0.150430
2    0.150385
3    0.143776
4    0.143473
5    0.143502
6    0.143474
dtype: float64
3    14629
2     2039
1     1580
Name: 7, dtype: int64
