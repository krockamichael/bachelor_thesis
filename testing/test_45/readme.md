encoder layers: non-trainable
LSTM: 2
units_1: 128
units_2: 64
epochs: 1
autoencoder batch_size: 128
n_clusters: 20
clusters batch_size: 256
max iterations: 8000
tolerance threshold: 0.001
regularizers.l1(10e-5): LSTM layer 2
iteration: 140
delta_label: 0.0
Clustering training time: 230.5512502193451
0     0.051368
1     0.052601
2     0.053218
3     0.051627
4     0.054211
5     0.051969
6     0.051392
7     0.052239
8     0.052256
9     0.051403
10    0.052096
11    0.052996
12    0.053626
13    0.051646
14    0.051356
15    0.051364
16    0.057090
17    0.052952
18    0.052025
19    0.053509
dtype: float64
0     4850
9     2526
14    2275
6     1338
5     1003
3      981
10     815
7      649
17     534
13     497
11     452
8      419
15     402
18     384
2      325
4      227
12     196
19     136
1      127
16     112
Name: 20, dtype: int64
