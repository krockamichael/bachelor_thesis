encoder layers: non-trainable
LSTM: 2
neurons_1: 128
neurons_2: 64.0
epochs: 20
autoencoder batch_size: 128
n_clusters: 15
clusters batch_size: 256
max iterations: 8000
tolerance threshold: 0.001
regularizers.l1(10e-5): LSTM layer 2
iteration: 140
delta_label: 0.0
Clustering training time: 299.6753103733063
0     0.068393
1     0.069938
2     0.068625
3     0.068243
4     0.071837
5     0.075922
6     0.071162
7     0.068285
8     0.069726
9     0.070699
10    0.069483
11    0.070194
12    0.068539
13    0.069955
14    0.069269
dtype: float64
7     5336
0     2616
12    2389
3     1450
14    1045
2     1031
1      852
10     695
11     677
13     541
6      456
8      438
4      315
9      288
5      119
Name: 15, dtype: int64
