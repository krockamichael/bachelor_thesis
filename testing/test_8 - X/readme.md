encoder layers: non-trainable
LSTM: 2
neurons_1: 128
neurons_2: 64.0
epochs: 20
autoencoder batch_size: 128
n_clusters: 10
clusters batch_size: 256
max iterations: 8000
tolerance threshold: 0.001
regularizers.l1(10e-5): LSTM layer 2
Autoencoder training time: 2729.5789022999998
Clustering training time: 2585.661686897278
0    0.116292
1    0.117562
2    0.117092
3    0.117734
4    0.115808
5    0.117549
6    0.117156
7    0.116330
8    0.116863
9    0.116899
dtype: float64
3    6867
2    6671
8       2
Name: 10, dtype: int64
