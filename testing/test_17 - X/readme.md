encoder layers: non-trainable
LSTM: 2
neurons_1: 128
neurons_2: 64.0
epochs: 20
autoencoder batch_size: 128
n_clusters: 7
clusters batch_size: 256
max iterations: 8000
tolerance threshold: 0.001
regularizers.l1(10e-3): LSTM layer 2
Autoencoder training time: 3559.9366123
Clustering training time: 5663.705323457718
0    0.142682
1    0.142887
2    0.142903
3    0.142893
4    0.142900
5    0.142889
6    0.142900
dtype: float64
2    18248
Name: 7, dtype: int64
