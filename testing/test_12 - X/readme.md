encoder layers: non-trainable
LSTM: 2
neurons_1: 128
neurons_2: 64.0
epochs: 20
autoencoder batch_size: 128
n_clusters: 7
clusters batch_size: 256
max iterations: 8000
tolerance threshold: 0.001
regularizers.l1(10e-5): LSTM layer 2
Autoencoder training time: 3145.0850510999994
Clustering training time: 1626.7476816177368
0    0.156146
1    0.152009
2    0.151771
3    0.155451
4    0.155732
5    0.151045
6    0.149552
dtype: float64
0    11271
1     6977
Name: 7, dtype: int64
