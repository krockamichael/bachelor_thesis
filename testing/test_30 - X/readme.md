encoder layers: non-trainable
LSTM: 3
neurons_1: 128
neurons_2: 64.0
neurons_3: 32.0
epochs: 20
autoencoder batch_size: 128
n_clusters: 7
clusters batch_size: 256
max iterations: 8000
tolerance threshold: 0.001
regularizers.l1(10e-5): LSTM layer 2
Autoencoder training time: 5249.845869899999
iteration: 140
delta_label: 0.6329460762823323
Clustering training time: 410.2058959007263
0    0.142857
1    0.142857
2    0.142857
3    0.142857
4    0.142857
5    0.142857
6    0.142857
dtype: float64
0    14475
4     1593
1      921
2      401
5      363
3      282
6      213
Name: 7, dtype: int64
