encoder layers: trainable
LSTM: 2
neurons_1: 128
neurons_2: 64.0
epochs: 20
autoencoder batch_size: 128
n_clusters: 7
clusters batch_size: 128
max iterations: 8000
tolerance threshold: 0.001
regularizers.l1(10e-5): LSTM layer 1
Autoencoder training time: 3602.7998915999992
Clustering training time: 2428.3859918117523
0    0.835136
1    0.726684
2    0.857530
3    0.793718
4    0.738029
5    0.841482
6    0.832444
dtype: float64
4    6868
3    3619
0    2786
1    1678
2    1435
5    1081
6     781
Name: 7, dtype: int64
