encoder layers: non-trainable
LSTM: 2
neurons_1: 128
neurons_2: 64.0
epochs: 20
autoencoder batch_size: 128
n_clusters: 7
clusters batch_size: 256
max iterations: 8000
tolerance threshold: 0.001
regularizers.l1(10e-5): LSTM layer 2
0    0.170041
1    0.162889
2    0.159492
3    0.173349
4    0.185273
5    0.159240
6    0.160149
dtype: float64
2    5731
5    3866
3    3233
1    2177
6    2030
0    1095
4     116
Name: 7, dtype: int64
