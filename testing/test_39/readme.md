encoder layers: non-trainable
LSTM: 2
neurons_1: 128
neurons_2: 64.0
epochs: 20
autoencoder batch_size: 128
n_clusters: 20
clusters batch_size: 256
max iterations: 8000
tolerance threshold: 0.001
regularizers.l1(10e-5): LSTM layer 2
iteration: 140
delta_label: 0.0
Clustering training time: 323.7946388721466
0     0.050335
1     0.050250
2     0.050294
3     0.051229
4     0.050172
5     0.050217
6     0.050414
7     0.050292
8     0.050270
9     0.050457
10    0.050651
11    0.050147
12    0.050268
13    0.050253
14    0.050221
15    0.050323
16    0.050240
17    0.050139
18    0.050839
19    0.050342
dtype: float64
17    4089
13    1367
1     1347
2     1228
12    1086
4      926
14     907
19     857
9      815
11     777
6      679
7      647
16     620
10     611
0      560
8      471
5      440
15     339
18     298
3      184
Name: 20, dtype: int64
